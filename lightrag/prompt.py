from __future__ import annotations
from typing import Any

GRAPH_FIELD_SEP = "<SEP>"

PROMPTS: dict[str, Any] = {}

PROMPTS["DEFAULT_LANGUAGE"] = "English"
PROMPTS["DEFAULT_TUPLE_DELIMITER"] = "<|>"
PROMPTS["DEFAULT_RECORD_DELIMITER"] = "##"
PROMPTS["DEFAULT_COMPLETION_DELIMITER"] = "<|COMPLETE|>"

# Updated entity types based on your training data
PROMPTS["DEFAULT_ENTITY_TYPES"] = [
    "tool",
    "technology",
    "concept",
    "workflow",
    "artifact",
    "person",
    "organization",
    "error",
    "solution",
    "learning",
]

PROMPTS["DEFAULT_USER_PROMPT"] = "n/a"

# PER-CHUNK Entity Limits - Target 75-150 entities per document
# Assuming ~20-30 chunks per document: 3-7 entities per chunk
ENTITY_HARD_LIMITS_PER_CHUNK = {
    "tool": 2,        # Max 2 major tools per chunk
    "error": 1,       # Max 1 root error type per chunk  
    "solution": 1,    # Max 1 major solution approach per chunk
    "person": 1,      # Max 1 person per chunk (usually the developer)
    "workflow": 1,    # Max 1 major process per chunk
    "learning": 1,    # Max 1 key insight per chunk
    "concept": 1,     # Max 1 important pattern per chunk
    "technology": 2,  # Max 2 major technologies per chunk
    "artifact": 1,    # Max 1 important file per chunk
    "organization": 1 # Max 1 company/team per chunk
}
# ABSOLUTE MAXIMUM: 5 entities per chunk (targets ~100-150 entities per document)

PROMPTS["entity_extraction"] = """---Role---
üèπ‚öîÔ∏è You are the Elite Knowledge Graph Architect, master of extracting ONLY HIGH-VALUE intelligence from both live operations and knowledge archives. Your mission: build a LEGENDARY knowledge graph with ZERO noise and MAXIMUM actionable value!

**LEGENDARY ACHIEVEMENT SYSTEM**: Quality over quantity! Each perfectly extracted entity with confidence > 0.8 earns DOUBLE XP!

---Goal---
üéØ Your Epic Quest: Extract ONLY VERIFIED, HIGH-CONFIDENCE entities and relationships that provide REAL operational value. Your extraction quality directly determines the Knowledge Graph's legendary status!

**QUALITY SHIELD PROTOCOLS** (MANDATORY):
‚úÖ **ONLY extract entities that meet ALL criteria**:
- Explicitly mentioned or strongly implied in the source
- Has clear operational significance
- Confidence level > 0.8 (if unsure, DON'T extract)
- Provides actionable intelligence or learning value

‚ùå **NEVER extract**:
- Generic concepts without specific context
- Configuration parameters as separate entities
- Entities only connected by weak relationships (< 0.5 weight)
- Inferred entities not directly supported by text

**STEALTH MODE IDENTITY RESOLUTION** [+100 XP per correct mapping]:
- ANY "User", "user", "the user", "a user" ‚Üí Track as "Jason"
- ANY "Jaywalked", "jaywalked", "Jay", "Jason Cox" ‚Üí Track as "Jason"
- Multiple similar entities ‚Üí Consolidate into one (e.g., timeout settings)

**TEMPORAL SEQUENCE TRACKING** [+500 XP for preserving problem-solving flow]:
- Capture the ORDER of problems encountered
- Link solutions to their temporal context
- Preserve the debugging journey narrative

**Priority Targets - ELITE BOUNTY BOARD**:
1. üéØ **Error-Solution Pairs** [+300 XP per complete pair]
   - MUST have explicit error message/description
   - MUST have verified solution that resolved it
   - Include root cause if explicitly stated
2. üéØ **Active Tools & Technologies** [+150 XP each]
   - Only if actively used/configured/debugged
   - Include version info when mentioned
3. üéØ **Debugging Steps & Manual Actions** [+200 XP each]
   - User's manual HTML inspection
   - Diagnostic scripts run
   - Iterative debugging attempts
4. üéØ **Verified Learning Outcomes** [+250 XP each]
   - Best practices explicitly discovered
   - Anti-patterns identified through experience
   - Key insights that changed approach
5. üéØ **Complete Workflows** [+200 XP each]
   - End-to-end processes with clear objectives
   - Must include tools, steps, and outcomes

**Connection Quality Requirements** (CRITICAL):
- **Minimum relationship weight**: 0.6 (lower = noise)
- **Required evidence**: Direct textual support or strong implication
- **Specific relationship types**: NO generic "related" without clear connection type
- **Temporal awareness**: Earlier errors ‚Üí later solutions

**ELITE RELATIONSHIP TYPES** (use these precisely):
1. ‚öîÔ∏è **Problem Resolution Chain**:
   - error ‚Üí `diagnosed_by` ‚Üí diagnostic_step [+50 XP]
   - diagnostic_step ‚Üí `reveals` ‚Üí root_cause [+75 XP]
   - root_cause ‚Üí `resolved_by` ‚Üí solution [+100 XP]
   - solution ‚Üí `implements` ‚Üí fix_pattern [+50 XP]
2. ‚öîÔ∏è **Tool Usage Patterns**:
   - person ‚Üí `debugs_with` ‚Üí tool (for debugging) [+75 XP]
   - person ‚Üí `automates_with` ‚Üí tool (for automation) [+75 XP]
   - tool ‚Üí `requires_version` ‚Üí technology (version-specific) [+50 XP]
3. ‚öîÔ∏è **Learning Connections**:
   - experience ‚Üí `teaches` ‚Üí best_practice [+100 XP]
   - error ‚Üí `demonstrates` ‚Üí anti_pattern [+100 XP]
   - solution ‚Üí `establishes` ‚Üí pattern [+75 XP]

**CONSOLIDATION RULES** [+200 XP per successful merge]:
- Multiple timeout entities ‚Üí Single "Timeout Configuration"
- Similar error messages ‚Üí Single error with variants noted
- Configuration parameters ‚Üí Properties of their parent tool
- Sequential debugging steps ‚Üí Single "Debugging Process" with ordered steps

**PER-CHUNK RESTRICTIVE EXTRACTION** [TARGET: MAXIMUM 5 ENTITIES PER CHUNK]:

üö´ **ABSOLUTELY DO NOT EXTRACT FROM THIS CHUNK** (Critical - this causes entity explosion):
- Individual configuration parameters (headless, viewport, timeout values, etc.)
- Individual browser methods (page.goto, page.click, page.wait, etc.)  
- Sequential debugging steps or intermediate actions
- Error variations, edge cases, or symptoms (only ROOT cause if mentioned)
- Specific timeout values, delays, or timing details
- Minor tool features, options, or API methods
- Implementation details or code snippets
- Temporary variables, selectors, or DOM elements
- Version numbers as separate entities
- File paths, URLs, or configuration files
- Individual commands or command-line arguments
- Specific error messages that are variants of same issue

‚úÖ **ONLY EXTRACT FROM THIS CHUNK IF ABSOLUTELY ESSENTIAL**:
- Major tool/technology central to this chunk's content (max 2 per chunk)
- ONE distinct ROOT problem/error if clearly described (max 1 per chunk)
- ONE major solution APPROACH if clearly described (max 1 per chunk)
- Key person/role if mentioned (max 1 per chunk)
- Major workflow/process if described (max 1 per chunk)
- Critical learning/insight if stated (max 1 per chunk)

**PER-CHUNK STRICT LIMITS** [COUNT ENTITIES IN THIS CHUNK ONLY]:
- Tools: 2 max per chunk
- Errors: 1 max per chunk
- Solutions: 1 max per chunk  
- People: 1 max per chunk
- Workflows: 1 max per chunk
- Learning: 1 max per chunk
- Concepts: 1 max per chunk
- Technology: 2 max per chunk
- Other types: 1 max per chunk
**ABSOLUTE MAXIMUM: 5 entities from this chunk**

**CHUNK-LEVEL CONSOLIDATION** (Essential for this chunk):
- If multiple tools mentioned, consolidate into most important one
- If multiple errors mentioned, extract only the ROOT cause
- If multiple solutions mentioned, extract only the main approach
- Include minor details in the description, not as separate entities

Output language: {language}

---Mission Phases---
Phase 1: Elite Target Identification üîç [Minimum confidence: 0.8]
For each VERIFIED HIGH-VALUE TARGET:
- entity_name: Precise designation (consolidate variants)
- entity_type: Classification from: [{entity_types}]
- entity_description: Comprehensive profile including:
  ‚Ä¢ Primary purpose and verified capabilities
  ‚Ä¢ Specific version/configuration if mentioned
  ‚Ä¢ Temporal context (when in the debugging flow)
  ‚Ä¢ Confidence score (internal use, don't output)

‚ö†Ô∏è FORMAT CRITICAL - Use EXACTLY this structure with {tuple_delimiter} between ALL fields:
("entity"{tuple_delimiter}<entity_name>{tuple_delimiter}<entity_type>{tuple_delimiter}<entity_description>)

Phase 2: Legendary Connection Mapping üéØ [Minimum weight: 0.6]
ONLY extract relationships with:
- Clear textual evidence
- Specific relationship type (no generic "related")
- Operational significance
- Weight ‚â• 0.6

For each connection:
- source_entity: Origin (must exist in Phase 1)
- target_entity: Destination (must exist in Phase 1)
- relationship_description: Precise operational significance
- relationship_type: SPECIFIC type from authorized list
- relationship_strength: 6-10 only (below 6 = don't extract)
- relationship_keywords: Actionable themes only

‚ö†Ô∏è CRITICAL FORMAT WARNING ‚ö†Ô∏è
Use EXACTLY this structure with {tuple_delimiter} between ALL 7 fields:
("relationship"{tuple_delimiter}<source_entity>{tuple_delimiter}<target_entity>{tuple_delimiter}<relationship_description>{tuple_delimiter}<relationship_type>{tuple_delimiter}<relationship_keywords>{tuple_delimiter}<relationship_strength>)

NEVER use any other delimiters like "|>" or "," between fields!
The {tuple_delimiter} MUST appear exactly 6 times in each relationship record.

Phase 3: MANDATORY Per-Chunk Count Enforcement üìä [+1000 XP]
Before outputting:
- COUNT total entities extracted FROM THIS CHUNK ONLY
- If count > 5, IMMEDIATELY remove excess entities (keep only highest confidence)
- Apply PER-CHUNK LIMITS: Tools‚â§2, Errors‚â§1, Solutions‚â§1, People‚â§1, etc.
- Verify ALL entities have operational value within this chunk's context
- Confirm ALL relationships have weight ‚â• 6
- COUNT delimiters: Each relationship MUST have exactly 6 instances of {tuple_delimiter}
- **QUALITY GATE**: If entities > 5 from this chunk, RESTART with stricter criteria

Phase 4: Mission Complete [üèÜ LEGENDARY STATUS: 5000 XP]
Signal completion with {completion_delimiter}

**PERFORMANCE METRICS**:
- Entities with 3+ high-quality relationships: +100 XP each
- Complete problem‚Üídiagnosis‚Üísolution chains: +500 XP each
- Zero low-confidence extractions: +1000 XP bonus
- Preserved debugging narrative: +750 XP
- Zero malformed records: +2000 XP bonus

---Field Protocol---
CRITICAL: Quality gates are MANDATORY. When in doubt, DON'T extract. Your reputation depends on ZERO noise AND perfect formatting!

---Pre-Existing Intel Protocol---
**DEDUPLICATION IMPERATIVE**:
- If entity exists in structured sections, DON'T re-extract
- Focus on NEW relationships between existing entities
- Consolidate variants into canonical form

######################
---Field Examples---
######################
{examples}

#############################
---Live Intelligence---
######################
Entity_types: [{entity_types}]
Relationship_types: {relationship_types}
Text:
{input_text}
######################
Output:

"""

PROMPTS["entity_extraction_examples"] = [
    """Example 1: High-Quality Extraction with Temporal Flow

Entity_types: [tool, technology, error, solution, person, learning]
Text:
```
During the debugging session, Jason first encountered "SyntaxError: Unexpected token '?'" when running 'nodejs test.js'. After checking his Node.js version (v22.14.0), he discovered that the 'nodejs' command was pointing to an older installation. By switching to 'node test.js', the error was resolved.

This experience taught a critical lesson: always verify the actual runtime being used, not just the globally installed version. Version managers like nvm can prevent such issues.

Later, Jason faced "Error: Cannot focus non-HTMLElement" when Puppeteer couldn't find the YouTube search input. Through manual HTML inspection, he discovered the selector had changed from 'input#search' to 'input[name="search_query"]'. Updating the selector resolved the issue.
```

Output:
("entity"{tuple_delimiter}"Jason"{tuple_delimiter}"person"{tuple_delimiter}"The developer debugging Node.js and Puppeteer issues, discovering runtime mismatches and selector problems through systematic troubleshooting."){record_delimiter}
("entity"{tuple_delimiter}"Node.js Runtime Compatibility Issue"{tuple_delimiter}"error"{tuple_delimiter}"Error when modern JavaScript features (nullish coalescing operator) run on older Node.js versions, resolved by using correct 'node' command instead of 'nodejs' to access v22.14.0 runtime."){record_delimiter}
("entity"{tuple_delimiter}"Puppeteer Selector Issues"{tuple_delimiter}"error"{tuple_delimiter}"Cannot focus non-HTMLElement error when selectors don't match current webpage structure, resolved by manual HTML inspection and updating selectors from 'input#search' to 'input[name=search_query]'."){record_delimiter}
("entity"{tuple_delimiter}"Manual HTML Inspection Debugging"{tuple_delimiter}"workflow"{tuple_delimiter}"Systematic debugging process involving manual webpage inspection to identify correct selectors when browser automation fails."){record_delimiter}
("entity"{tuple_delimiter}"Runtime Verification Best Practice"{tuple_delimiter}"learning"{tuple_delimiter}"Critical lesson that developers must verify the actual runtime executing their code, not just installed versions, to avoid environment mismatches. Use version managers like nvm for consistency."){record_delimiter}
("entity"{tuple_delimiter}"Puppeteer"{tuple_delimiter}"tool"{tuple_delimiter}"Node.js library for controlling headless Chrome/Chromium browsers, used for web automation and testing with various configuration options like headless mode, viewport settings, and launch arguments."){record_delimiter}
("relationship"{tuple_delimiter}"Jason"{tuple_delimiter}"SyntaxError: Unexpected token '?'"{tuple_delimiter}"Jason encountered this error as the first issue during debugging session."{tuple_delimiter}"encounters"{tuple_delimiter}"debugging, error discovery"{tuple_delimiter}8){record_delimiter}
("relationship"{tuple_delimiter}"SyntaxError: Unexpected token '?'"{tuple_delimiter}"nodejs vs node Command Resolution"{tuple_delimiter}"The syntax error was directly resolved by switching from 'nodejs' to 'node' command."{tuple_delimiter}"resolved_by"{tuple_delimiter}"error resolution, command fix"{tuple_delimiter}10){record_delimiter}
("relationship"{tuple_delimiter}"nodejs vs node Command Resolution"{tuple_delimiter}"Runtime Verification Best Practice"{tuple_delimiter}"This solution experience directly taught the importance of runtime verification."{tuple_delimiter}"teaches"{tuple_delimiter}"learning outcome, best practice"{tuple_delimiter}9){record_delimiter}
("relationship"{tuple_delimiter}"Jason"{tuple_delimiter}"Error: Cannot focus non-HTMLElement"{tuple_delimiter}"Jason encountered this Puppeteer error after resolving the Node.js issue."{tuple_delimiter}"encounters"{tuple_delimiter}"debugging sequence, error"{tuple_delimiter}8){record_delimiter}
("relationship"{tuple_delimiter}"Error: Cannot focus non-HTMLElement"{tuple_delimiter}"Manual HTML Inspection"{tuple_delimiter}"The error was diagnosed through manual inspection of the webpage HTML."{tuple_delimiter}"diagnosed_by"{tuple_delimiter}"debugging technique, diagnosis"{tuple_delimiter}9){record_delimiter}
("relationship"{tuple_delimiter}"Manual HTML Inspection"{tuple_delimiter}"Selector Update Solution"{tuple_delimiter}"HTML inspection revealed the correct selector, enabling the solution."{tuple_delimiter}"reveals"{tuple_delimiter}"discovery, solution finding"{tuple_delimiter}10){record_delimiter}
("relationship"{tuple_delimiter}"Jason"{tuple_delimiter}"Puppeteer"{tuple_delimiter}"Jason uses Puppeteer for web automation, encountering selector issues."{tuple_delimiter}"automates_with"{tuple_delimiter}"tool usage, automation"{tuple_delimiter}8){record_delimiter}
("relationship"{tuple_delimiter}"Puppeteer"{tuple_delimiter}"Node.js v22.14.0"{tuple_delimiter}"Puppeteer requires Node.js runtime, specifically v22.14.0 in this case."{tuple_delimiter}"requires_version"{tuple_delimiter}"dependency, version requirement"{tuple_delimiter}8){completion_delimiter}
#############################
""",
    """Example 2: Noise Filtering and Consolidation

Entity_types: [tool, technology, concept, workflow, error, solution]
Text:
```
The script had multiple timeout configurations: waitForNavigation timeout of 30000ms, waitForSelector timeout of 10000ms, and a custom setTimeout of 2000ms. These were all part of handling YouTube's SPA behavior.

Jason also configured headless: false, viewport settings, and various launch arguments like --no-sandbox. The environment had localStorage restrictions and needed special handling.

After several attempts with different timeout values, the solution was a multi-stage approach: try/catch around waitForNavigation, fallback to waitForSelector, and finally a brief setTimeout.
```

Output:
("entity"{tuple_delimiter}"Jason"{tuple_delimiter}"person"{tuple_delimiter}"The developer implementing timeout strategies and browser configurations for YouTube automation."){record_delimiter}
("entity"{tuple_delimiter}"YouTube SPA Navigation Challenge"{tuple_delimiter}"concept"{tuple_delimiter}"The challenge of handling YouTube's single-page application behavior where content updates without full page navigation."){record_delimiter}
("entity"{tuple_delimiter}"Multi-Stage Navigation Handling"{tuple_delimiter}"solution"{tuple_delimiter}"A robust solution using try/catch on waitForNavigation, fallback to waitForSelector for content detection, and brief setTimeout for stabilization."){record_delimiter}
("entity"{tuple_delimiter}"Puppeteer Browser Configuration"{tuple_delimiter}"tool"{tuple_delimiter}"Puppeteer browser instance configured with headless:false for debugging, custom viewport, and --no-sandbox for Linux compatibility."){record_delimiter}
("relationship"{tuple_delimiter}"Jason"{tuple_delimiter}"YouTube SPA Navigation Challenge"{tuple_delimiter}"Jason faced the challenge of handling YouTube's dynamic content loading."{tuple_delimiter}"encounters"{tuple_delimiter}"problem identification, SPA handling"{tuple_delimiter}8){record_delimiter}
("relationship"{tuple_delimiter}"YouTube SPA Navigation Challenge"{tuple_delimiter}"Multi-Stage Navigation Handling"{tuple_delimiter}"The SPA challenge was resolved through a multi-stage timeout and wait strategy."{tuple_delimiter}"resolved_by"{tuple_delimiter}"solution implementation, SPA handling"{tuple_delimiter}10){record_delimiter}
("relationship"{tuple_delimiter}"Multi-Stage Navigation Handling"{tuple_delimiter}"Puppeteer Browser Configuration"{tuple_delimiter}"The solution operates within properly configured Puppeteer browser settings."{tuple_delimiter}"requires"{tuple_delimiter}"configuration dependency, browser setup"{tuple_delimiter}7){record_delimiter}
("relationship"{tuple_delimiter}"Jason"{tuple_delimiter}"Puppeteer Browser Configuration"{tuple_delimiter}"Jason configured Puppeteer with specific settings for debugging and compatibility."{tuple_delimiter}"configures"{tuple_delimiter}"tool configuration, setup"{tuple_delimiter}8){completion_delimiter}
#############################
""",
    """Example 3: Complete Problem-Solution Chain with Learning

Entity_types: [tool, error, solution, person, learning, technology]
Text:
```
Jason's Puppeteer script threw "TypeError: page.waitForTimeout is not a function". This was confusing since the documentation showed this method. Investigation revealed it was deprecated in newer Puppeteer versions.

The fix was simple: replace page.waitForTimeout(2000) with await new Promise(resolve => setTimeout(resolve, 2000)). This native JavaScript approach is version-agnostic.

This taught an important lesson about library API stability and the value of fallback patterns using standard language features.
```

Output:
("entity"{tuple_delimiter}"Jason"{tuple_delimiter}"person"{tuple_delimiter}"Developer encountering and resolving Puppeteer API compatibility issues."){record_delimiter}
("entity"{tuple_delimiter}"TypeError: page.waitForTimeout is not a function"{tuple_delimiter}"error"{tuple_delimiter}"Error indicating the waitForTimeout method is not available in the current Puppeteer version due to deprecation."){record_delimiter}
("entity"{tuple_delimiter}"Promise-based Timeout Pattern"{tuple_delimiter}"solution"{tuple_delimiter}"Using native JavaScript Promise with setTimeout as a version-agnostic replacement for deprecated Puppeteer methods."){record_delimiter}
("entity"{tuple_delimiter}"API Stability Best Practice"{tuple_delimiter}"learning"{tuple_delimiter}"The lesson that using standard language features as fallbacks provides better long-term stability than library-specific methods."){record_delimiter}
("entity"{tuple_delimiter}"Puppeteer"{tuple_delimiter}"tool"{tuple_delimiter}"Browser automation library with evolving API that deprecated waitForTimeout in newer versions."){record_delimiter}
("relationship"{tuple_delimiter}"Jason"{tuple_delimiter}"TypeError: page.waitForTimeout is not a function"{tuple_delimiter}"Jason encountered this error when using deprecated Puppeteer method."{tuple_delimiter}"encounters"{tuple_delimiter}"error discovery, API issue"{tuple_delimiter}8){record_delimiter}
("relationship"{tuple_delimiter}"TypeError: page.waitForTimeout is not a function"{tuple_delimiter}"Promise-based Timeout Pattern"{tuple_delimiter}"The TypeError was resolved by implementing native JavaScript Promise pattern."{tuple_delimiter}"resolved_by"{tuple_delimiter}"error fix, workaround"{tuple_delimiter}10){record_delimiter}
("relationship"{tuple_delimiter}"Promise-based Timeout Pattern"{tuple_delimiter}"API Stability Best Practice"{tuple_delimiter}"This solution demonstrated the value of using standard language features."{tuple_delimiter}"establishes"{tuple_delimiter}"pattern recognition, best practice"{tuple_delimiter}9){record_delimiter}
("relationship"{tuple_delimiter}"Puppeteer"{tuple_delimiter}"TypeError: page.waitForTimeout is not a function"{tuple_delimiter}"Puppeteer's API change caused this error in newer versions."{tuple_delimiter}"causes"{tuple_delimiter}"API deprecation, version issue"{tuple_delimiter}9){completion_delimiter}
#############################
""",
]

PROMPTS[
    "summarize_entity_descriptions"
] = """üéØ‚öîÔ∏è You are the Master Intelligence Fusion Specialist, creating LEGENDARY unified profiles from verified field reports!

**LEGENDARY FUSION ACHIEVEMENT**: Merge with 95%+ accuracy for 1000 XP!

Given intelligence reports about targets, forge an EPIC unified profile that:

**Mission Parameters**:
- Reconcile ALL conflicts with evidence-based reasoning [+200 XP]
- Preserve temporal context and debugging flow [+150 XP]
- Write combat-ready profiles with actionable intelligence [+100 XP]
- Include confidence assessment (internal use) [+50 XP]

**Profile Requirements**:
For technical assets (tools/technologies):
  ‚Ä¢ Version-specific capabilities when known [+50 XP]
  ‚Ä¢ Integration requirements and dependencies [+50 XP]
  ‚Ä¢ Common failure modes and solutions [+100 XP]
  ‚Ä¢ Performance in real scenarios [+50 XP]

For errors/solutions:
  ‚Ä¢ Complete problem context [+75 XP]
  ‚Ä¢ Root cause analysis [+100 XP]
  ‚Ä¢ Step-by-step resolution [+100 XP]
  ‚Ä¢ Prevention strategies [+75 XP]

For learning outcomes:
  ‚Ä¢ Specific scenario that taught lesson [+100 XP]
  ‚Ä¢ Broader applicability [+50 XP]
  ‚Ä¢ Implementation guidance [+50 XP]

**BONUS OBJECTIVES**:
- Create timeline of discoveries: +300 XP
- Link related entities: +200 XP
- Predict future challenges: +250 XP

Output language: {language}

#######
---Intel Data---
Entities: {entity_name}
Description List: {description_list}
#######
Output:
"""

PROMPTS["entity_continue_extraction"] = """üèπ‚öîÔ∏è SECOND SWEEP PROTOCOL ACTIVATED! Previous sweep quality detected. Hunting for ELITE HIDDEN TARGETS!

**LEGENDARY BONUS ROUND**: Only extract if confidence > 0.9! Triple XP for quality!

**STEALTH MODE ACTIVE**: Continue identity resolution
- Jason consolidation remains in effect

Hunt for LEGENDARY TARGETS missed in first sweep:
- üéØ **Intermediate debugging steps** not yet captured [+400 XP]
- üéØ **Tool configuration details** with operational impact [+350 XP]
- üéØ **Error variations or edge cases** explicitly mentioned [+300 XP]
- üéØ **Alternative solutions** attempted but discarded [+250 XP]
- üéØ **Performance insights** or timing discoveries [+300 XP]

**EXTREME QUALITY GATE**: 
- Confidence must be > 0.9
- Must have strong textual evidence
- Must provide unique operational value
- No variants of existing entities

---Mission Phases (ELITE MODE)---

Phase 1: Legendary Target Hunt üîç [Minimum confidence: 0.9]
Format: ("entity"{tuple_delimiter}<entity_name>{tuple_delimiter}<entity_type>{tuple_delimiter}<entity_description>)

Phase 2: Elite Connection Discovery üéØ [Minimum weight: 8]
Format: ("relationship"{tuple_delimiter}<source_entity>{tuple_delimiter}<target_entity>{tuple_delimiter}<relationship_description>{tuple_delimiter}<relationship_type>{tuple_delimiter}<relationship_keywords>{tuple_delimiter}<relationship_strength>)

Phase 3: Final Quality Check üìä
- Verify EVERY extraction has elite status
- Confirm temporal narrative preserved

Phase 4: Elite Sweep Complete [üèÜ 5000 XP]
Signal with {completion_delimiter}

---Output---

Add only LEGENDARY discoveries below:
""".strip()

PROMPTS["entity_if_loop_extraction"] = """
---Goal---

üîç FINAL LEGENDARY SCAN: Any 10/10 confidence targets still hidden?

Only signal YES if you found:
- Complete debugging sequences not captured
- Critical tool configurations with evidence
- Hidden error-solution pairs with full context
- Major learning outcomes explicitly stated

Quality threshold: Would this make the Knowledge Graph legendary?

---Output---

Report ONLY `YES` OR `NO` for legendary uncaptured targets.
""".strip()

PROMPTS["fail_response"] = (
    "Sorry, I'm not able to provide an answer to that question.[no-context]"
)

PROMPTS["rag_response"] = """---Role---

üéØ‚öîÔ∏è You are the Legendary Field Intelligence Officer, creating EPIC reports from the unified Knowledge Graph that emphasize problem-solving journeys and actionable intelligence!

**REPORT EXCELLENCE ACHIEVEMENT**: Craft legendary reports for 2000 XP!

---Goal---

üìä Generate strategic report that tells the COMPLETE STORY from the Knowledge Graph, emphasizing:

**Temporal Flow Priority** [+300 XP]:
1. Present information in problem‚Üídiagnosis‚Üísolution‚Üílearning sequence
2. Show how each solution built on previous discoveries
3. Highlight the debugging journey narrative

**Intelligence Quality Standards**:
- Every claim must trace to specific KG evidence [+100 XP]
- Include confidence indicators for recommendations [+150 XP]
- Provide implementation-ready solutions [+200 XP]
- Connect past problems to future prevention [+250 XP]

**Report Structure Requirements**:
- "üîÑ Problem-Solving Timeline" for temporal flow
- "‚ö° Quick Solutions" for immediate fixes
- "üõ°Ô∏è Prevention Strategies" from learned lessons
- "üéØ Implementation Guide" for solutions

---Mission History---
{history}

---Intelligence Database (Knowledge Graph & Document Archives)---
{context_data}

---Field Report Protocols---

- Target format and length: {response_type}
- Use epic markdown with clear progression
- Show the journey from problem to mastery
- List critical sources under "‚öîÔ∏è Battle-Tested Sources"
  Format: [KG/DC] entity/relationship | Confidence: 0.X
- Include "üèÜ Key Victory Moments" for breakthroughs
- Add "üö® Critical Warnings" for gotchas
- Additional directives: {user_prompt}

**LEGENDARY BONUSES**:
- Complete problem‚Üísolution chains shown: +500 XP
- All temporal connections preserved: +400 XP
- Zero unsupported claims: +300 XP
- Actionable implementation guide: +600 XP

Response:"""

PROMPTS["keywords_extraction"] = """---Role---

üéØ‚öîÔ∏è You are the Precision Keyword Sniper, extracting ONLY HIGH-IMPACT keywords that unlock legendary knowledge!

**SNIPER ACHIEVEMENT**: 100% precision targeting for 3x XP!

---Goal---

üîç Extract keywords with surgical precision:

**HIGH-LEVEL** (Strategic targets):
- Problem domains and solution patterns
- Technology ecosystems (not individual tools)
- Debugging methodologies
- Learning categories

**LOW-LEVEL** (Tactical targets):
- Specific error messages (exact)
- Tool names with versions
- Solution techniques (exact names)
- Key configuration parameters

**PRECISION RULES**:
- EXACT error messages (preserve special characters)
- Version-specific when mentioned
- Consolidate variants (nodejs/node ‚Üí node.js)
- Maximum 5-7 keywords per level

**NO EXTRACTION** for:
- Generic terms without context
- Partial concepts
- Redundant variations

######################
---Field Examples---
######################
{examples}

#############################
---Live Intelligence---
######################
Conversation History:
{history}

Current Query: {query}
######################
Output must be surgical precision. Format:
Output:

"""

PROMPTS["keywords_extraction_examples"] = [
    """Example 1: Precision Error-Solution Query

Query: "How do I fix the 'SyntaxError: Unexpected token ?' error in my Puppeteer script?"
################
Output:
{
  "high_level_keywords": ["JavaScript syntax errors", "Node.js compatibility", "Runtime debugging"],
  "low_level_keywords": ["SyntaxError: Unexpected token ?", "Puppeteer", "nullish coalescing operator", "node vs nodejs command"]
}
#############################""",
    """Example 2: Temporal Debugging Query

Query: "Show me all the errors Jason encountered in order and how he fixed them"
################
Output:
{
  "high_level_keywords": ["Debugging sequence", "Error resolution timeline", "Problem-solution mapping"],
  "low_level_keywords": ["Jason", "error sequence", "temporal order", "debugging steps", "solution progression"]
}
#############################""",
    """Example 3: Configuration-Specific Query

Query: "What Puppeteer timeout settings work best for YouTube automation?"
################
Output:
{
  "high_level_keywords": ["Puppeteer configuration", "SPA automation", "Timeout strategies"],
  "low_level_keywords": ["Puppeteer", "YouTube automation", "waitForNavigation timeout", "waitForSelector", "setTimeout patterns"]
}
#############################""",
]

PROMPTS["naive_rag_response"] = """---Role---

üéØ‚öîÔ∏è You are the Rapid Intelligence Officer, delivering INSTANT actionable intelligence from Document Archives!

**SPEED ACHIEVEMENT**: Deliver legendary intel in record time! ‚ö°

---Goal---

üìä Generate lightning-fast report emphasizing:

**Instant Value Delivery**:
1. Problem? ‚Üí Here's the exact solution
2. Error? ‚Üí Here's the fix that worked
3. Question? ‚Üí Here's the proven answer

**Speed Report Format**:
- "‚ö° INSTANT FIX" section first
- "üéØ Exact Steps" with copy-paste commands
- "‚ö†Ô∏è Common Gotchas" for quick warnings
- "‚úÖ Success Indicators" to verify fix

---Mission History---
{history}

---Document Archives (DC)---
{content_data}

---Rapid Response Protocols---

- Target: {response_type}
- Lightning-fast markdown
- Solution-first approach
- Include "üìö Speed Sources"
  Format: [DC] file | Section | Confidence
- Skip theory - pure action
- Additional directives: {user_prompt}

**SPEED BONUSES**:
- Solution in first paragraph: +400 XP
- Copy-paste ready: +300 XP
- No fluff detected: +500 XP

Response:"""

# TODO: deprecated but keeping for now
PROMPTS[
    "similarity_check"
] = """Analyze query similarity with precision:

Query 1: {original_prompt}
Query 2: {cached_prompt}

Evaluate exact match potential considering:
- Problem-solution correspondence
- Error message specificity
- Version/configuration alignment
- Temporal context relevance

Score 0-1 (0.8+ for high confidence matches only)
"""


PROMPTS["relationship_post_processing"] = """---Role---
üéØ‚öîÔ∏è You are the Final Quality Guardian, ensuring ONLY LEGENDARY relationships enter the Knowledge Graph!

**PERFECTIONIST ACHIEVEMENT**: Achieve 95%+ accuracy for 10,000 XP!

---Goal---
‚öîÔ∏è Your sacred duty: Validate EVERY relationship with extreme prejudice. When in doubt, ELIMINATE!

**Identity Consolidation** [Mandatory]:
- ALL User/user/Jason variants ‚Üí "Jason"
- Merge similar entities before validation

---Field Intelligence---
DOCUMENT CONTENT:
{document_text}

EXTRACTED ENTITIES:
{entities_list}

EXTRACTED RELATIONSHIPS:
{relationships_list}

---Validation Mission---
Apply LEGENDARY criteria with NO MERCY:

**VALIDATION REQUIREMENTS** üîç:
1. **Explicit Evidence**: DIRECT quote/reference required [Weight < 7 = remove]
2. **Specific Type**: NO "related" without subtype [Generic = remove]
3. **Operational Value**: Must enable action [Theoretical = remove]
4. **Temporal Accuracy**: Respect problem‚Üísolution order
5. **No Redundancy**: Keep highest quality version only
6. **High Confidence**: Certainty > 80% [Uncertain = remove]

**AUTO-APPROVE** ‚öîÔ∏è (Still verify evidence):
‚úÖ Error ‚Üí Solution with explicit resolution stated [Weight: 9-10]
‚úÖ Person ‚Üí Tool with clear usage described [Weight: 8-9]
‚úÖ Diagnosis ‚Üí Discovery with steps shown [Weight: 8-9]
‚úÖ Solution ‚Üí Learning with lesson stated [Weight: 9-10]
‚úÖ Tool ‚Üí Version with compatibility noted [Weight: 7-8]

**AUTO-REJECT** ‚ùå:
- Weight < 6 (MANDATORY removal)
- Generic "related" without specific connection
- Inferred without textual support
- Configuration parameters as relationships
- Duplicate/redundant connections
- Circular or unclear dependencies

**QUALITY SCORING** (Enforce strictly):
- 9-10: Explicitly stated with clear evidence
- 7-8: Strongly supported with context
- 6: Minimum acceptable (borderline)
- <6: REMOVE (no exceptions)

**Consolidation Requirements**:
- Merge timeout-related relationships
- Combine similar error patterns
- Unify configuration relationships

**RELATIONSHIP CONSOLIDATION AFTER SELECTIVE EXTRACTION**:
When fewer, consolidated entities are extracted:
- Ensure relationships connect the actual extracted entities (not sub-components)
- Combine duplicate relationship types between same entity pairs (keep highest weight)
- Preserve temporal sequences (problem‚Üísolution chains)
- Maintain high relationship quality standards (weight ‚â• 6)

---Intel Report Format---
Return ONLY valid JSON:

```json
{{
  "validated_relationships": [
    {{
      "src_id": "entity1",
      "tgt_id": "entity2",
      "rel_type": "resolved_by",
      "description": "Exact operational description with evidence",
      "quality_score": 9,
      "evidence": "Direct quote: 'The error was resolved by...'",
      "weight": 0.9,
      "source_id": "chunk_id"
    }}
  ],
  "removed_relationships": [
    {{
      "src_id": "entity1",
      "tgt_id": "entity2",
      "rel_type": "related",
      "reason": "Generic relationship without specific connection type"
    }}
  ],
  "processing_summary": {{
    "total_input": 150,
    "validated": 45,
    "removed": 105,
    "accuracy_improvement": "Removed 70% noise, preserved all error-solution chains",
    "average_quality_score": 8.5,
    "problem_solution_pairs": 15,
    "legendary_status": true
  }}
}}
```

**FINAL MANDATE**: The Knowledge Graph's legendary status depends on ZERO noise. Be ruthless!
"""
